[
    {
        "author_name": "Thaís França",
        "author_url": "https://medium.com/@francethais",
        "published_at": "2023-12-18 16:45:17.246000",
        "reading_time_minutes": 2.3349056603773586,
        "story_url": "https://medium.com/@francethais/databricks-92d8b1c8dc0a",
        "subtitle": "Usando python",
        "title": "Databricks",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "Serge Smertin",
        "author_url": "https://medium.com/@nf-x",
        "published_at": "2023-12-21 23:34:55.731000",
        "reading_time_minutes": 1.6301886792452829,
        "story_url": "https://medium.com/databricks-labs/ucx-v0-7-0-by-databricks-labs-new-release-with-cli-commands-b4ddd0786598",
        "subtitle": "Another week and another release of UCX sees the light of day!",
        "title": "UCX v0.7.0 by Databricks Labs — new release with CLI commands",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "Databricks SQL SME",
        "author_url": "https://medium.com/@databricks_sql_sme",
        "published_at": "2023-12-20 18:28:56.034000",
        "reading_time_minutes": 6.1141509433962264,
        "story_url": "https://medium.com/dbsql-sme-engineering/migrate-to-databricks-with-lakehouse-utils-dbt-package-v2-streamlined-6d52874075c9",
        "subtitle": "Author(s): Cody Austin Davis & Roberto Salcido",
        "title": "Migrate to Databricks with Lakehouse Utils DBT Package — V2 Streamlined",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "Jon Wiggins",
        "author_url": "https://medium.com/@jonisavg",
        "published_at": "2023-12-19 15:20:06.808000",
        "reading_time_minutes": 0.2490566037735849,
        "story_url": "https://medium.com/@jonisavg/install-or-import-python-package-66da83cdb722",
        "subtitle": "This code snippet will allow you to programmatically check to see if you need to first Install your Python Package, or if it exists, import…",
        "title": "Install or Import Python Package?",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "Pallavi Sinha",
        "author_url": "https://medium.com/@pallavisinha12",
        "published_at": "2023-12-21 06:40:37.902000",
        "reading_time_minutes": 6.2650943396226415,
        "story_url": "https://medium.com/@pallavisinha12/navigating-datas-timeline-with-delta-table-time-travel-f8a9d01a0c1d",
        "subtitle": "Delta Lake’s time travel feature is a powerful capability that allows users to access and query historical versions of data stored in Delta…",
        "title": "Navigating Data’s Timeline with Delta Table Time Travel",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "Vanderson Gonçalves",
        "author_url": "https://medium.com/@vnderson",
        "published_at": "2023-12-20 10:45:23.322000",
        "reading_time_minutes": 3.9132075471698116,
        "story_url": "https://medium.com/@vnderson/integrating-google-sheets-data-into-azure-databricks-lakehouse-with-logic-apps-part-1-8d383e5b1b49",
        "subtitle": "Despite the evolution of Data Analytics and the widespread adoption of new technologies for processing data, there are instances when users…",
        "title": "Integrating Google Sheets data into Azure Databricks Lakehouse with Logic Apps - Part 1",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "Benoit Pothier",
        "author_url": "https://medium.com/@bpothier",
        "published_at": "2023-12-18 16:36:43.236000",
        "reading_time_minutes": 4.267924528301887,
        "story_url": "https://medium.com/@bpothier/kilibas-data-stack-migration-to-databricks-achieving-a-tenfold-efficiency-in-machine-learning-ce5e41a6b8d1",
        "subtitle": "Introduction",
        "title": "Kiliba’s Data Stack Migration to Databricks: Achieving a Tenfold efficiency in Machine Learning…",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "Kevin Courbet",
        "author_url": "https://medium.com/@kevin.courbet",
        "published_at": "2023-12-20 10:54:15.638000",
        "reading_time_minutes": 5.445283018867925,
        "story_url": "https://medium.com/@kevin.courbet/how-blue-systems-leveraged-the-databricks-ecosystem-to-quickly-go-to-market-b8f056f3d7a8",
        "subtitle": "In a fast-moving world where shared usage is replacing ownership, flow optimization and curb infrastructure access management are the main…",
        "title": "How Blue Systems leveraged the Databricks ecosystem to quickly go to market",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "InnovateForge",
        "author_url": "https://medium.com/@InnovateForge",
        "published_at": "2023-12-18 16:53:42.895000",
        "reading_time_minutes": 2.8254716981132075,
        "story_url": "https://medium.com/@InnovateForge/deploying-large-language-models-llms-using-databricks-2c5f98374a1f",
        "subtitle": "Large Language Models (LLMs) have revolutionized the field of natural language processing, enabling a wide range of applications from…",
        "title": "Deploying Large Language Models (LLMs) using Databricks",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "RocketMan",
        "author_url": "https://medium.com/@jo5hua",
        "published_at": "2023-12-21 08:36:18.867000",
        "reading_time_minutes": 3.158490566037736,
        "story_url": "https://medium.com/@jo5hua/spark-structured-streaming-from-confluent-kafka-using-azure-databricks-05cc50b78668",
        "subtitle": "Are you new to big data? Your business expects you to get data from machines to be uploaded into a cloud environment ?",
        "title": "Spark structured streaming from Confluent Kafka using Azure Databricks",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "InnovateForge",
        "author_url": "https://medium.com/@InnovateForge",
        "published_at": "2023-12-18 16:58:42.088000",
        "reading_time_minutes": 1.3132075471698113,
        "story_url": "https://medium.com/@InnovateForge/how-to-estimate-the-cost-of-provisioned-throughput-model-serving-experience-in-foundation-model-017e20ba533e",
        "subtitle": "To estimate the cost of provisioned throughput model serving experience in Foundation Model APIs, you need to consider several factors:",
        "title": "How to estimate the cost of provisioned throughput model serving experience in foundation model…",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "InnovateForge",
        "author_url": "https://medium.com/@InnovateForge",
        "published_at": "2023-12-18 16:55:40.621000",
        "reading_time_minutes": 1.6113207547169812,
        "story_url": "https://medium.com/@InnovateForge/optimizing-large-language-model-llm-on-databricks-0d7c472f100e",
        "subtitle": "Optimizing Large Language Model (LLM) serving on Databricks involves several steps that can significantly improve throughput and latency…",
        "title": "Optimizing Large Language Model (LLM) on Databricks",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "Anupam Chand",
        "author_url": "https://medium.com/@anupamchand",
        "published_at": "2023-12-21 08:48:43.725000",
        "reading_time_minutes": 6.489622641509434,
        "story_url": "https://anupamchand.medium.com/pyspark-data-frame-quality-validation-framework-in-databricks-using-great-expectations-hands-on-5fd0b070ea09",
        "subtitle": "We all know how important data quality for a data platform and data analysis. Databricks in one of popular platforms used to conduct ETL…",
        "title": "Pyspark data frame quality validation framework in Databricks using Great Expectations(hands on)",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "Prof. Dr. Caio Moreno",
        "author_url": "https://medium.com/@caiomsouza",
        "published_at": "2023-12-20 20:53:47.676000",
        "reading_time_minutes": 0.4037735849056604,
        "story_url": "https://caiomsouza.medium.com/llmops-everything-you-need-to-know-to-manage-llms-ff0a1ee653be",
        "subtitle": "Dear LLM community,",
        "title": "LLMOps: Everything You Need to Know to Manage LLMs",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "Jingyun Chen",
        "author_url": "https://medium.com/@jyc7115",
        "published_at": "2023-12-20 01:33:42.400000",
        "reading_time_minutes": 1.760691823899371,
        "story_url": "https://medium.com/@jyc7115/run-multiple-notebooks-inside-one-notebook-on-databricks-platform-17d02b05525b",
        "subtitle": "In Databricks, if we want to run a notebook inside another notebook, we usually use the magic command `%run`. It works fine in most cases…",
        "title": "Run multiple notebooks inside one notebook on Databricks platform",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "Josemanuelgarciagimenez",
        "author_url": "https://medium.com/@josemanuelgarciagimenez",
        "published_at": "2023-12-19 12:50:37.907000",
        "reading_time_minutes": 9.955660377358491,
        "story_url": "https://medium.com/@josemanuelgarciagimenez/implementing-data-quality-with-databricks-2b15d89d3fa5",
        "subtitle": "Data quality is one of the key factors that we need to consider when designing our data platform. It is one of the core pillars of data…",
        "title": "Implementing data quality with Databricks",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "Antonio Aliaga",
        "author_url": "https://medium.com/@antaliagacortes",
        "published_at": "2023-12-20 14:06:22.941000",
        "reading_time_minutes": 5.857547169811321,
        "story_url": "https://medium.com/@antaliagacortes/introduction-to-databricks-lakehouse-monitoring-aebeddf013b5",
        "subtitle": "Databricks Lakehouse Monitoring, currently on preview, stands out as one of the tools organizations can benefit to incorporate statistics…",
        "title": "Introduction to Databricks Lakehouse monitoring",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "Ambassador of Newland",
        "author_url": "https://medium.com/@ambassador-of-newland",
        "published_at": "2023-12-20 15:08:16.668000",
        "reading_time_minutes": 9.890566037735848,
        "story_url": "https://blog.tdg.international/mlflow-managing-the-life-cycle-of-machine-learning-projects-fe475c80f587",
        "subtitle": "Machine learning projects are complex and require a delicate balance of numerous components. MLflow is an open-source platform developed by…",
        "title": "MLflow: Managing the Life Cycle of Machine Learning Projects",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "Bysanitribhuvan",
        "author_url": "https://medium.com/@bysanitribhuvan",
        "published_at": "2023-12-20 16:22:51.029000",
        "reading_time_minutes": 1.1622641509433962,
        "story_url": "https://medium.com/@bysanitribhuvan/how-to-load-modified-data-from-data-bricks-to-sql-or-blob-storages-7d0fd5aed4cb",
        "subtitle": "Introduction:",
        "title": "How To Load Modified Data from Data Bricks to (SQL OR Blob) storages",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    },
    {
        "author_name": "Shubham Rana",
        "author_url": "https://medium.com/@shubham-rana",
        "published_at": "2023-12-21 09:48:53.644000",
        "reading_time_minutes": 2.968238993710692,
        "story_url": "https://medium.com/@shubham-rana/snowbricks-a-tale-of-two-houses-part-1-61f831f32cfd",
        "subtitle": "House Snowflake or House Databricks, who will rule us all?",
        "title": "Snowbricks: A Tale of Two Houses— Part 1",
        "extraction_id": "7d0ebe4a-e529-4417-8db9-1b90fd9e31ff",
        "extracted_at": "2023-12-22 06:18:27.352315",
        "extracted_at_epoch": 1703225907,
        "extraction_url": "https://medium.com/tag/databricks/archive",
        "tag": "databricks"
    }
]